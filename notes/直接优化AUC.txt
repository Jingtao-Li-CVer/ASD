1. scale那篇的loss，在HYDICE数据集上，表现出极高的可分离度，背景几乎只有蓝色

只有auc优化： 峰值0.977
只有交叉熵：0.985

二者皆有： 0.992最高 似乎AUCHingeloss不影响峰值，但可以降低虚警

发现实现的是AUCPR优化，需要实现AUCROC （不过AUCPR更适合正样本少的情况）

（另外，鉴于TDD背景偏离度无法控制的问题，加入偏移度控制。同时，实验中发现有些目标和背景的偏移度，和其他地方的负样本内部之间
偏移度相似/觉得还是要探测出来）

优化AUCHingeloss，输出不能是sigmoid之后的，应该是以0为均值的值，得改下

改成了优化AUCROC，考虑到异常样本小比例，强化了约束条件。证明了凸优性（关于L凸，关于lambda凹，以及整体的有界性）

TDDv1可分离性低的表现可以看可分离性图

目前架构的decoder部分 全用的G（后期改成交替的），只返回注意力图（防止全部是蓝的现象）
Hinge loss探测不出来黄色区域的两个点
Sigmoid loss可以探测出来，但两个最高都是0.89左右

理论上，HingeLoss可以保证最大分离，SIgmoid loss具备noisy-tolerance的能力

新问题：为什么搞着搞着就搞反了？


教师和学生网络一致

标签数据使用之前过滤掉的，教师网络使用交叉熵，然后过滤掉低置信度。
1. GRX的AUC比Local RX高，所以采用GRX的探测图，0.5为阈值，构造伪


标签。联合AUC和交叉熵，第一个epoch可以达到0.945
2. hydice迁移到park，与park迁移到hydice的reverse问题解决了，不采取归一化就行
3. 发现之前0.945的训练是有local RXD结果上预训练的参数，重新制作伪标签后，发现from scratch，local RXD伪标签结果比Global RXD好很多，很稳定。
而且AUC第一轮0.85，第二轮伪标签self training后达到了0.943。
4. 但是SNPR低了很多，后面发现HingeLoss 不如使用 sigmoid后做的hinge loss large margin。
5. 发现规律：从异质性低的数据迁移到高的数据，容易造成高虚警，从异常性高的数据迁移到低的数据，容易造成低探测率。Station 4cm/pixel Park 8 cm/pixel
这篇文章的结论讲到https://www.sciencedirect.com/topics/engineering/spatial-resolution， 
The contrast of the object with respect to its background affects the spatial resolution.
6 UDA的输入扰动，会导致模型输出固定的探测图，即坍塌。故可以看出，模型对扰动的容忍能力低（预训练的数据太少）。
Noisy student，也不能加输入noisy，制作伪标签的方式可以获得一定提升，但提升不大。 （原因可能是station数据内部异质性差异也很大，很多unlabeled data相当于out-of-distribution了，
而且self-training的第一步，即在有标签数据上学习的效果都还不好（loss都不低））
7 自回归的方式是学习一个条件概率，由于数据不同patch分布变化较大，条件概率来不及学，且不具备迁移性。
8 重新反思之前的经验，察觉可能是数据变化太快导致的，验证了每个数据持续重复训练10次，精度会有明显提升。

如果我们降低loss的方式可以工作，是因为做到了极度的均衡（正负样本，简单样本和困难样本），而且异质性高的样本迁移到低的样本是很容易的
吐了，发现竟然是数据有问题，重新修改了样本制作方式，现在生成的标签1应该是对的了（好像也不是这个问题）

使用RXD基础样本理由 1 异常的定义和高分特点导致会有很多其它异常，因此，过滤掉

目前的两个核心问题是 1 loss是否在降低，训练时的pred怎么样 2 训练好测试不行，说明模拟有问题(station很多亮度异常)
BCE的比例换成1：0.1, 以及使用IN代替BN后，效果好了很多。

对照GT发现，大部分其实都识别出来了（看来只打乱通道顺序可以迁移到辐射亮度异常），只是两个区域没识别出来（一个就是暗的，一个是）

再次印证，所提loss是为了提升探测率和large margin和SNPR


学生网络需要加入dropout，随机深度，输入上本身就是加上随机性和伪标签的，loss的话还是采用交叉熵

设计的TDDv1基础上的随机扰动，是一个很鲁棒的点

发现两个制约关系：探测率和虚警率的制约，但是HAD的虚警很不一样，所以选择牺牲部分虚警；此外就是训练影像AUC和测试影像AUC，训练高到一定程度过拟合，测试AUC会降低

训练和测试时间肯定要对比下

直接优化，收敛速度很快