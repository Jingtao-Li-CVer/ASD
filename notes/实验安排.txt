题目： 遥感场景理解的异常分割模型


1 需要一个图展示一些argriculture vision的各个类别模式
2 argriculture vision所有类别依次作为normal的实验，计算AUC，其次筛选一些效果图作为结果图
3 松材线虫数据
4 另外在LoveDA上展示一下处理image-level级别的探测AUC，例如loveDA上
5 


消融实验（表格和结果图）
1 scales 个数和范围，可视化分析1x1卷积权重
2 loss函数，单独的和联合起来的
3 latent_dim 维度和训练时间和精度 10 50 100 200 300
4 采用的数据增强方式
5 训练集上t-SNE图随训练过程的变化
6 模型参数量，训练时间，推理时间


数据增强后的效果可以给个图展示
数据增强可以写得点，用的库
1 所有的数据增强分为Pixel-level和spatial-level
2 由于遥感特性，某些增强不能用

备选增强方案：RandomCrop， RandomGridShuffle ， ChannelShuffle  ， RandomBrightness


分析异常分数计算方法 与边界还是中心[论文这部分相关阐述要改一下]

测试计算loss的距离是中位数，四分卫点，最大值，平均还是xxx

定量定性每个尺度得到的anomaly map和fusion以后的anomaly map

R的初始值对结果影像也很大，经验上样本数量少设置为1，多设置为3

一些细节去释放，例如每个epoch保存每张影像最大的半径去更新。以及每次为了提升效率取了列的最大值（具体debug看下）

为什么不用全卷积而用patch，全卷积的空间对应关系是架构原因和损失一起构成的，
单独使用架构的对应关系不精细，需要额外使用loss约束，这是我们的分割和语义分割的区别之一，
另外，原理也不同

训练过程中重启是一个很重要的步骤

分析是不是都在球面附近,感觉是两个条件互相约束所致

引言写一下为什么不用直接生成异常分数的，依赖于负样本选取

要体现数据噪声和多尺度的特点

第二个数据集由于tiae之前用的数据增强没什么用，所以去除使用tiae，使用riad
发现auc评价有个问题，忽略了预测的概率值和模型的拟合优度，所以考虑把交叉熵代入计算

第一个数据集的损失比例是1：1，用的增强方式就是注释掉的, 
第二个比例是1：0.1， 用的增强方式是其它数据集, 

